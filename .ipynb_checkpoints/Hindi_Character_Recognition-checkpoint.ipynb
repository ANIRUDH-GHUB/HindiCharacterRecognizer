{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Models/devanagari_refined.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labels import labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising Camera and ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x00000205A7545760>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpgfsmq5p3.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x00000205A7545760>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpgfsmq5p3.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Opening Camera\n",
    "cap = cv2.VideoCapture(1)\n",
    "pred_class=0\n",
    "pts = deque(maxlen=512)\n",
    "blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "flag = True\n",
    "while flag:\n",
    "    # Read image\n",
    "    ret, frame = cap.read()\n",
    "    # Flip Image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # BGR2HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Extracting color from image\n",
    "    mask = cv2.inRange(hsv, np.array([38, 150, 50]), np.array([130, 150, 50]))\n",
    "    # Blurring image\n",
    "    median = cv2.medianBlur(mask, 15)\n",
    "    blur = cv2.GaussianBlur(median, (5,5), 0)\n",
    "    \n",
    "    # Threshold image\n",
    "    ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Finding Contours\n",
    "    contours, heirarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    center = None\n",
    "    \n",
    "    if len(contours) >= 1:\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(contour) > 250:\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(contour)\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "            M = cv2.moments(contour)\n",
    "            center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "            pts.appendleft(center)\n",
    "            for i in range(1, len(pts)):\n",
    "                if pts[i - 1] is None or pts[i] is None:\n",
    "                    continue\n",
    "                cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 10)\n",
    "                cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), 5)\n",
    "    \n",
    "    elif len(contours) == 0:\n",
    "        if len(pts) != []:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "            thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            blackboard_cnts, heirarchy_1 = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            if len(blackboard_cnts) >= 1:\n",
    "                cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                if cv2.contourArea(cnt) > 2000:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                    # newImage = process_letter(digit)\n",
    "                    \n",
    "                    im = cv2.resize(digit, (32, 32))\n",
    "                    im = np.array(im, dtype=np.float32)\n",
    "                    im = np.reshape(im, (-1, 32, 32, 1))\n",
    "                    pred_probab = model.predict(im)[0]\n",
    "                    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    cv2.putText(frame, \"Predicted Letter :  \" + str(labels[pred_class]), (10, 470),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Showing predictions\n",
    "    cv2.imshow('Frame',frame)\n",
    "    cv2.imshow(\"Contours\", thresh)\n",
    "      \n",
    "    # Taking input key\n",
    "    keypress = cv2.waitKey(1)\n",
    "        \n",
    "    # If \"q\" is pressed\n",
    "    # Terminate\n",
    "    if keypress == ord('q'):\n",
    "        flag = False\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
